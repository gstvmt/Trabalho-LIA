{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a747ef36",
   "metadata": {},
   "source": [
    "<div class='container2'>\n",
    "    <hr style=\"height:10px\"> \n",
    "    <h1 ALIGN='center'>Laboratório de Inovação e Automação 1 (LIA 1)</h1>\n",
    "    <h2 ALIGN='center'>Tema: Visao computacional</h2>\n",
    "    <h3 ALIGN='center'>Autores: Gustavo Mota Barros e Pedro Ferreira Galvao Neto</h3>\n",
    "    <hr style=\"height:10px\">\n",
    "    <img src='https://sp-ao.shortpixel.ai/client/to_auto,q_lossy,ret_img/https://blog.grvppe.com/wp-content/uploads/2019/12/Computer-Vision-pixforce-drone-1280x640.jpg' ALIGN='center' width=\"800\">\n",
    "    <hr style=\"height:10px\">\n",
    "</div>\n",
    "<div style=\"padding-left:20px; padding-right:20px;\">\n",
    "    <p style=\"font-size:16px; white\">\n",
    "        O projeto desenvolvido consiste na utilizaçao de modelos de inteligencia artificial voltados a area de visao computacional, para o reconhecimento de objetos. Este projeto demonstrará como o modelo se comporta em relacao a imagens e videos, alem de aplicaçoes que demonstram a grande utilidade destes modelos.\n",
    "    </p>\n",
    "</div>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43928017",
   "metadata": {},
   "source": [
    "# Aplicaçoes com o modelo de visao computacional YOLO V4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86070e",
   "metadata": {},
   "source": [
    "## Passos envolvidos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045be79",
   "metadata": {},
   "source": [
    "### Baixando os arquivos necessarios :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99ed0b",
   "metadata": {},
   "source": [
    "   Primeiro, como utilizaremos o modelo yolo v4 para o reconhecimento de imagens e videos com a biblioteca cv2 do openCV, devemos baixar os arquivos yolov4.weights e yolov4.cfg que sao disponibilizados no seguinte repositorio: https://github.com/AlexeyAB/darknet\n",
    "   Também, devemos baixar, neste repositorio, o arquivo coco.names que se encontra na pasta cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6938b",
   "metadata": {},
   "source": [
    "### Carregando o modelo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe89d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro, deve-se importar as seguintes bibliotecas\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import pafy\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efce4b",
   "metadata": {},
   "source": [
    "#### Carregando o modelo completo para a detecçao em imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce25b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando a rede neural\n",
    "net = cv2.dnn.readNet('yolov4.weights', 'yolov4.cfg')\n",
    "\n",
    "# criando o modelo a partir da rede neural\n",
    "model = cv2.dnn.DetectionModel(net)\n",
    "\n",
    "# setando os parametros de entrada para o modelo utilizado\n",
    "model.setInputParams(size=(608,608), scale=(1/255))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ed3c6",
   "metadata": {},
   "source": [
    "#### Carregando o modelo tiny para a detecçao em videos :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc42178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando a rede neural\n",
    "net = cv2.dnn.readNet('yolov4-tiny.weights', 'yolov4-tiny.cfg')\n",
    "\n",
    "# criando o modelo a partir da rede neural\n",
    "model = cv2.dnn.DetectionModel(net)\n",
    "\n",
    "# setando os parametros de entrada para o modelo utilizado\n",
    "model.setInputParams(size=(416,416), scale=(1/255))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04587b6b",
   "metadata": {},
   "source": [
    "### Carregando o arquivo de nomes das imagens reconhecidas pelo modelo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffcba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando os nomes para uma lista\n",
    "class_names = []\n",
    "with open('coco_names.txt','r') as f:\n",
    "    class_names = [cname.strip() for cname in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7de6c6",
   "metadata": {},
   "source": [
    "### Configurando as cores para cada classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b6d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo as cores de cada nome\n",
    "name_color = []\n",
    "for i in class_names:\n",
    "    color =(((sum(map(ord,i))*2)%255),((sum(map(ord,i))*3)%255),((sum(map(ord,i))*5)%255))\n",
    "    name_color.append(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c639c1",
   "metadata": {},
   "source": [
    "### Detectando objetos em Imagens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdf57ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite em ingles o nome do objeto que deseja testar:person\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n"
     ]
    }
   ],
   "source": [
    "# Primeiro devemos coletar a imagem a ser detectada\n",
    "#iremos usar o duckduckgo para isso\n",
    "\n",
    "from duckduckgo_search import ddg_images\n",
    "import requests\n",
    "\n",
    "def search_img(img_name, num_img=15):\n",
    "    ddg_img = ddg_images(img_name, max_results=num_img)\n",
    "    img_list = [dicio['image'] for dicio in ddg_img]\n",
    "    return img_list\n",
    "\n",
    "img_name = input(\"Digite em ingles o nome do objeto que deseja testar:\")\n",
    "\n",
    "if img_name not in class_names:\n",
    "    print(\"O modelo nao é capaz de reconhecer este objeto. Tente novamente!\")\n",
    "else:\n",
    "    images = search_img(img_name)\n",
    "    img_list = []\n",
    "    for i in images:\n",
    "        print(\"Carregando links validos...\")\n",
    "        try:\n",
    "            if requests.get(i).status_code in range(400,500):\n",
    "                images.remove(i)\n",
    "            else:\n",
    "                response = requests.get(i)\n",
    "                img_array = np.array(bytearray(response.content), dtype=np.uint8)\n",
    "                img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "                res_img = cv2.resize(img,(416,416))\n",
    "                img_list.append(res_img)\n",
    "        except:\n",
    "            images.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4235611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: person ---> score: 0.4117244482040405\n",
      "class: tie ---> score: 0.22676917910575867\n",
      "class: person ---> score: 0.9023652672767639\n",
      "class: tie ---> score: 0.6395965814590454\n",
      "class: person ---> score: 0.9572144746780396\n",
      "class: tie ---> score: 0.7818458080291748\n",
      "class: person ---> score: 0.861284077167511\n",
      "class: person ---> score: 0.9307529330253601\n",
      "class: person ---> score: 0.8180352449417114\n",
      "class: person ---> score: 0.951819121837616\n",
      "class: tie ---> score: 0.9398318529129028\n"
     ]
    }
   ],
   "source": [
    "# agora iremos realizar a detecçao na imagem\n",
    "\n",
    "for i in img_list:\n",
    "    model_image = i.copy()\n",
    "\n",
    "    classes, scores, boxes = model.detect(model_image , 0.1, 0.2)\n",
    "\n",
    "    for (classid, score, box) in zip(classes, scores, boxes):\n",
    "        color = name_color[classid]\n",
    "        label = f\"{class_names[classid]}: {score}\"\n",
    "\n",
    "        cv2.rectangle(model_image, box, color, 2)\n",
    "        cv2.putText(model_image, label, (box[0], box[1] + 15), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 2)\n",
    "        print(f\"class: {class_names[classid]} ---> score: {score}\")\n",
    "\n",
    "    cv2.imshow(\"detections\", model_image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d175c",
   "metadata": {},
   "source": [
    "### Detectando objetos em videos :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "129f57ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ecf53eb472457ba2476065db2fde2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Carregando Video:   0%|          | 0/180000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Para que o recurso de videos do youtube funcione, é necessario instalar a biblioteca youtube-dl e modificar o arquivo \n",
    "youtube.py que se encontra na pasta extractor, indo na linha 1794 e comentando-a. Apos isso, acesse a biblioteca pafy e comente\n",
    "as linhas 53, 54 e 55 do arquivo backend_youtube_dl.py '''\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=iBlRm6BzgqY&t=904s&ab_channel=LucasSousa\" #basta colocar o url do seu video aqui\n",
    "videoPafy = pafy.new(url)\n",
    "\n",
    "def getNormalQuality(videoPafy):\n",
    "    for stream in videoPafy.videostreams:\n",
    "        if stream.resolution == '1280x720' and stream.extension =='mp4':\n",
    "            return stream\n",
    "    return videoPafy.getbest(preftype='mp4')\n",
    "\n",
    "cap = cv2.VideoCapture(getNormalQuality(videoPafy).url)\n",
    "filename = 'test_video.mp4'\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "test_out = cv2.VideoWriter(filename, codec, 30, (1280, 720))\n",
    "\n",
    "duration = 180*1000 # duraçao do video em milissegundos\n",
    "pbar = tqdm(total=duration , desc=\"Carregando Video: \")\n",
    "n = 0\n",
    "k = 0\n",
    "while True:\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    test_out.write(frame)\n",
    "    \n",
    "    vid_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    n = vid_time - k\n",
    "    k = vid_time\n",
    "    pbar.update(n)\n",
    "    \n",
    "    if vid_time >= duration or not _:\n",
    "        break\n",
    "\n",
    "test_out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "698d9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('test_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d22c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que a fluidez do video seja mantida iremos escrever um arquivo mp4 com as detecçoes ao inves de faze-la\n",
    "# simultaneamente\n",
    "\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "vid_out = cv2.VideoWriter('result.mp4', codec, 30, (1280, 720))\n",
    "\n",
    "file = open(\"detec.csv\", 'w', newline='', encoding= 'utf-8')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['Frame', 'Objeto', 'Score', 'x_pos', 'y_pos'])\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    _, f = cap.read()\n",
    "    start = time.time()\n",
    "    classes, scores, boxes = model.detect(f,0.1,0.2)\n",
    "    end = time.time()\n",
    "\n",
    "    for (classid, score, box) in zip(classes, scores, boxes):\n",
    "        color = name_color[classid]\n",
    "        label = f\"{class_names[classid]}: {score}\"\n",
    "        writer.writerow([cap.get(cv2.CAP_PROP_POS_MSEC), class_names[classid], score, (box[0] + int(box[2]/2)), \n",
    "                        (box[1] + int(box[3]/2))])\n",
    "        \n",
    "        cv2.rectangle(f, box, color, 2)\n",
    "        cv2.putText(f, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    fps_label = f\"FPS: {round((1/(end - start)),2)}\"\n",
    "\n",
    "    cv2.putText(f, fps_label, (0,25), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,0), 5)\n",
    "    cv2.putText(f, fps_label, (0,25), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 3)\n",
    "    \n",
    "    vid_out.write(f)\n",
    "    cv2.imshow(\"Video Detection\",f)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27 or not _:\n",
    "        break\n",
    "\n",
    "file.close()\n",
    "vid_out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb0a6a",
   "metadata": {},
   "source": [
    "### Detectando objetos na camera :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3a894",
   "metadata": {},
   "source": [
    "#### Capturando a webcam do computador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea67278",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =  cv2.VideoCapture(0) # aqui vai o numero referente ao dispositivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b851d",
   "metadata": {},
   "source": [
    "#### Capturando a camera do celular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f310e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =  cv2.VideoCapture(\"http://192.168.1.3:4747/video\") # aqui vai o numero referente ao dispositivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d576317",
   "metadata": {},
   "source": [
    "#### Detecçao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41df689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo de detecçao\n",
    "while cap.isOpened():\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    start = time.time()\n",
    "    classes, scores, boxes = model.detect(frame,0.1,0.2)\n",
    "    end = time.time()\n",
    "\n",
    "    for (classid, score, box) in zip(classes, scores, boxes):\n",
    "        color = name_color[classid]\n",
    "        label = f\"{class_names[classid]}: {score}\"\n",
    "        \n",
    "        cv2.rectangle(frame, box, color, 2)\n",
    "        cv2.putText(frame, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    fps_label = f\"FPS: {round((1/(end - start)),2)}\"\n",
    "\n",
    "    cv2.putText(frame, fps_label, (0,25), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,0), 5)\n",
    "    cv2.putText(frame, fps_label, (0,25), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 3)\n",
    "\n",
    "    cv2.imshow(\"detections\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
