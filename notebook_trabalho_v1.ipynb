{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a747ef36",
   "metadata": {},
   "source": [
    "<div class='container2'>\n",
    "    <hr style=\"height:10px\"> \n",
    "    <h1 ALIGN='center'>Laboratório de Inovação e Automação 1 (LIA 1)</h1>\n",
    "    <h2 ALIGN='center'>Visao computacional</h2>\n",
    "    <h3 ALIGN='center'>Autores: Gustavo Mota Barros e Pedro Ferreira Galvao Neto</h3>\n",
    "    <hr style=\"height:10px\">\n",
    "    <img src='https://sp-ao.shortpixel.ai/client/to_auto,q_lossy,ret_img/https://blog.grvppe.com/wp-content/uploads/2019/12/Computer-Vision-pixforce-drone-1280x640.jpg' ALIGN='center' width=\"800\">\n",
    "    <hr style=\"height:10px\">\n",
    "</div>\n",
    "<div style=\"padding-left:20px; padding-right:20px;\">\n",
    "    <p style=\"font-size:16px; white\">\n",
    "        O projeto desenvolvido consiste na utilizaçao de modelos de inteligencia artificial voltados a area de visao computacional, para o reconhecimento de objetos. Este projeto demonstrará como o modelo se comporta em relacao a imagens e videos, alem de aplicaçoes que demonstram a grande utilidade destes modelos.\n",
    "    </p>\n",
    "</div>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43928017",
   "metadata": {},
   "source": [
    "# Aplicaçoes com o modelo de visao computacional YOLO V4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86070e",
   "metadata": {},
   "source": [
    "## Passos envolvidos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045be79",
   "metadata": {},
   "source": [
    "### Baixando os arquivos necessarios :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99ed0b",
   "metadata": {},
   "source": [
    "   Primeiro, como utilizaremos o modelo yolo v4 para o reconhecimento de imagens e videos com a biblioteca cv2 do openCV, devemos baixar os arquivos yolov4.weights e yolov4.cfg que sao disponibilizados no seguinte repositorio: https://github.com/AlexeyAB/darknet\n",
    "   Também, devemos baixar, neste repositorio, o arquivo como.names que se encontra na pasta cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6938b",
   "metadata": {},
   "source": [
    "### Carregando o modelo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe89d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro, deve-se importar as seguintes bibliotecas\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce25b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando os pesos do modelo\n",
    "# net = cv2.dnn.readNet('yolov4-tiny.weights', 'yolov4-tiny.cfg') # para a  versao tiny\n",
    "\n",
    "net = cv2.dnn.readNet('yolov4.weights', 'yolov4.cfg') # para a versao padrao(mais pesada)\n",
    "\n",
    "# criando o modelo\n",
    "model = cv2.dnn.DetectionModel(net)\n",
    "\n",
    "# setando os parametros de entrada para o modelo utilizado\n",
    "# model.setInputParams(size=(416,416), scale=(1/255)) # para o modelo tiny\n",
    "\n",
    "model.setInputParams(size=(608,608), scale=(1/255)) # para o modelo padrao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04587b6b",
   "metadata": {},
   "source": [
    "### Carregando o arquivo de nomes das imagens reconhecidas pelo modelo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffcba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando os nomes para uma lista\n",
    "class_names = []\n",
    "with open('coco_names.txt','r') as f:\n",
    "    class_names = [cname.strip() for cname in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7de6c6",
   "metadata": {},
   "source": [
    "### Configurando as cores para cada classe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b6d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo as cores de cada nome\n",
    "name_color = []\n",
    "for i in class_names:\n",
    "    color =(((sum(map(ord,i))*2)%255),((sum(map(ord,i))*3)%255),((sum(map(ord,i))*5)%255))\n",
    "    name_color.append(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb0a6a",
   "metadata": {},
   "source": [
    "### Detectando objetos em videos :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea67278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primeiro devemos escolher o video que queremos detectar\n",
    "'''cap =  cv2.VideoCapture(\"teste_carros.mp4\")''' # aqui vai algum video do diretoria ou alguma camera conectada no dispositivo\n",
    "\n",
    "# tambem podemos selecionar um video diretamente do youtube\n",
    "''' Para que o recurso de videos do youtube funcione, é necessario instalar a biblioteca youtube-dl e modificar o arquivo \n",
    "youtube.py que se encontra na pasta extractor, indo na linha 1794 e comentando-a. Apos isso, acesse a biblioteca pafy e comente\n",
    "as linhas 53, 54 e 55 do arquivo backend_youtube_dl.py '''\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=bSor87AYTM0&ab_channel=4KUrbanLife\" #basta colocar o url do seu video aqui\n",
    "videoPafy = pafy.new(url)\n",
    "best = videoPafy.getbest(preftype=\"mp4\")\n",
    "\n",
    "cap = cv2.VideoCapture(best.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41df689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo de detecçao\n",
    "while cap.isOpened():\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    start = time.time()\n",
    "    classes, scores, boxes = model.detect(frame,0.1,0.2)\n",
    "    end = time.time()\n",
    "\n",
    "    for (classid, score, box) in zip(classes, scores, boxes):\n",
    "        color = name_color[classid]\n",
    "        label = f\"{class_names[classid]}: {score}\"\n",
    "        \n",
    "        cv2.rectangle(frame, box, color, 2)\n",
    "        cv2.putText(frame, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    fps_label = f\"FPS: {round((1/(end - start)),2)}\"\n",
    "\n",
    "    cv2.putText(frame, fps_label, (0,25), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,0), 5)\n",
    "    cv2.putText(frame, fps_label, (0,25), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 3)\n",
    "\n",
    "    cv2.imshow(\"detections\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c639c1",
   "metadata": {},
   "source": [
    "### Detectando objetos em Imagens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf57ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite em ingles o nome do objeto que deseja testar:person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gumot\\AppData\\Roaming\\Python\\Python310\\site-packages\\duckduckgo_search\\compat.py:60: UserWarning: ddg_images is deprecated. Use DDGS().images() generator\n",
      "  warnings.warn(\"ddg_images is deprecated. Use DDGS().images() generator\")\n",
      "C:\\Users\\Gumot\\AppData\\Roaming\\Python\\Python310\\site-packages\\duckduckgo_search\\compat.py:64: UserWarning: parameter page is deprecated\n",
      "  warnings.warn(\"parameter page is deprecated\")\n",
      "C:\\Users\\Gumot\\AppData\\Roaming\\Python\\Python310\\site-packages\\duckduckgo_search\\compat.py:66: UserWarning: parameter max_results is deprecated\n",
      "  warnings.warn(\"parameter max_results is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n",
      "Carregando links validos...\n"
     ]
    }
   ],
   "source": [
    "# Primeiro devemos coletar a imagem a ser detectada\n",
    "#iremos usar o duckduckgo para isso\n",
    "from duckduckgo_search import ddg_images\n",
    "import requests\n",
    "\n",
    "def search_img(img_name, num_img=15):\n",
    "    ddg_img = ddg_images(img_name, max_results=num_img)\n",
    "    img_list = [dicio['image'] for dicio in ddg_img]\n",
    "    return img_list\n",
    "\n",
    "img_name = input(\"Digite em ingles o nome do objeto que deseja testar:\")\n",
    "\n",
    "if img_name not in class_names:\n",
    "    print(\"O modelo nao é capaz de reconhecer este objeto. Tente novamente!\")\n",
    "else:\n",
    "    images = search_img(img_name)\n",
    "    for i in images:\n",
    "        print(\"Carregando links validos...\")\n",
    "        try:\n",
    "            if requests.get(i).status_code in range(400,500):\n",
    "                images.remove(i)\n",
    "        except:\n",
    "            images.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407cd308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionando algumas das imagens carregadas\n",
    "url = images[3] #aqui voce mudar os indices para testar outras imagens\n",
    "\n",
    "response = requests.get(url)\n",
    "img_array = np.array(bytearray(response.content), dtype=np.uint8)\n",
    "img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "res_img = cv2.resize(img,(416,416))\n",
    "cv2.imshow(\"Imagem Selecionada\", res_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4235611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: person ---> score: 0.9981570243835449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora iremos realizar a detecçao na imagem\n",
    "\n",
    "model_image = res_img.copy()\n",
    "\n",
    "classes, scores, boxes = model.detect(model_image , 0.1, 0.2)\n",
    "\n",
    "for (classid, score, box) in zip(classes, scores, boxes):\n",
    "    color = name_color[classid]\n",
    "    label = f\"{class_names[classid]}: {score}\"\n",
    "        \n",
    "    cv2.rectangle(model_image, box, color, 2)\n",
    "    cv2.putText(model_image, label, (box[0], box[1] + 15), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 2)\n",
    "    print(f\"class: {class_names[classid]} ---> score: {score}\")\n",
    "        \n",
    "\n",
    "cv2.imshow(\"detections\", model_image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
